{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicycler is taking too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen how long it took for Unicycler is taking too long for long read genome assembly. Should I actually wait? Well, I did a separate job (hybrid assembly on the same data) on another computer, and it has been over 5 days. How can we solve this?\n",
    "\n",
    "- Use a bigger instance?\n",
    "- Use more instances?\n",
    "- Subsample the data?\n",
    "\n",
    "By summing up the length of reads, the Nanopore data would have 5 Gbp. The size of the <em>E. coli</em> K12 MG1655 is 4.64 Mbp - thus we could have assembled the genome with over 1000X coverage. That is overkill for a genome assembly - [Ryan Wick](https://nanoporetech.com/resource-centre/completing-bacterial-genome-and-plasmid-assemblies) assembled the <em>Klebsiella pneumoniae</em> isolate INF177 with only 28X depth.\n",
    "\n",
    "I settled with 30X (153.9 Mbp) on our own HPC (15 cores) and it worked within 1 hour and 16 minutes. I repeated for 100X coverage, on 32 cores, and it finished in 21 minutes, which is great! Subsampling the data would reduce the computational hours required, and increasing the number of cores definitely would make things even faster. However, we have not yet assessed the quality of the assembly - that we will do in another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of the tutorial, I will demonstrate how it would look like doing it on AWS using the 30X subsampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, hybrid genome assembly using both 30X and Illumina reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using AWS allows a lot of freedom in scaling up the computational power, but you have to pay for their services. I was quite at liberty using EC2 because the alarm billing that I set didn't trigger - so I let the instance run overnight. Turn's out because of the POC I was using, the alarm wouldn't trigger, and based AWS Cost Explorer I have actually spent $71 in the span of 3 days.\n",
    "\n",
    "This is quite shocking to me. So, in the next notebooks, we will try and look into spot pricing in AWS, which should cut the price, as low as 90% discount. Using spot pricing, we can afford to use even bigger instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
